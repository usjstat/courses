

---
title: "Chapter 6 Approximating the Posterior"
author: "Dr. Rajitha M. Silva"
output: html_document
---

---
title: "Unit 2: Bayesian Computation - Grid Approximation and MCMC"
author: "Dr. Rajitha M. Silva"
output:
  html_document:
    number_sections: true
    theme: readable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Welcome to Unit 2!

Unit 2 serves as a critical bridge to applying the fundamental concepts from Unit 1 in the more sophisticated model settings of Unit 3 and beyond. 

In Unit 1, we learned to think like Bayesians and to build some fundamental Bayesian models in this spirit. Further, by cranking these models through Bayes’ Rule, we were able to mathematically specify the corresponding posteriors.

Those days are over. Though merely hypothetical for now, some day (starting in Chapter 9) the models we’ll be interested in analyzing will get too complicated to mathematically specify.

Never fear – data analysts are not known to throw up their hands in the face of the unknown. When we can’t know or specify something, we approximate it. In Unit 2 we’ll explore **Markov chain Monte Carlo (MCMC)** simulation techniques for approximating otherwise out-of-reach posterior models.

## Posterior Analysis: Motivation

Whether we’re able to specify or must approximate a posterior model, we must then be able to understand and apply the results. To this end, we learned how to describe our posterior understanding using model features such as **central tendency** and **variability** in Unit 1.

Yet in practice, we typically want to perform a deeper posterior analysis. This process revolves around three major elements:

- **Posterior estimation**  
- **Hypothesis testing**  
- **Prediction**

## Conceptual Leaps in Bayesian Learning

You’ve already taken a few leaps:

- From Chapter 2 to 3: simple discrete priors → continuous Beta priors
- From Chapter 3 to 5: Beta-Binomial model → more general Bayesian families

Each leap makes your Bayesian toolkit more powerful, but also more mathematically demanding.

### A Realistic Scenario: Michelle for President

In Chapter 3 you built a model of Michelle’s support in Minnesota. Now consider refining that analysis by modeling Michelle’s support in all 50 states + D.C. Incorporate past voting trends and demographics.

Let $\boldsymbol{\theta} = (\theta_1, \theta_2, \dots, \theta_k)$ represent the $k \geq 1$ parameters of this more complex Bayesian model. We wish to study the posterior:

$$
f(\boldsymbol{\theta} \mid \mathbf{y}) = \frac{f(\boldsymbol{\theta}) L(\boldsymbol{\theta} \mid \mathbf{y})}{f(\mathbf{y})} \propto f(\boldsymbol{\theta}) L(\boldsymbol{\theta} \mid \mathbf{y})
$$

But computing the normalizing constant:

$$
f(\mathbf{y}) = \int_{\theta_1} \int_{\theta_2} \cdots \int_{\theta_k} f(\boldsymbol{\theta}) L(\boldsymbol{\theta} \mid \mathbf{y}) d\theta_k \cdots d\theta_1
$$

is intractable for large $k$.

# Simulation to the Rescue

When closed-form posteriors are infeasible, we approximate via simulation.

We’ll explore two techniques:

- **Grid Approximation**
- **Markov Chain Monte Carlo (MCMC)**

When done well, both produce a sample of $N$ posterior values:

$$
\{ \boldsymbol{\theta}^{(1)}, \boldsymbol{\theta}^{(2)}, \dots, \boldsymbol{\theta}^{(N)} \}
$$

with properties that reflect those of the true posterior distribution.

## Goals of Unit 2

- Implement and examine limitations of grid approximation
- Explore MCMC properties and distinguish from grid approximation
- Implement MCMC in **R**
- Learn Markov chain diagnostics to assess MCMC quality

# Load Required Packages

```{r packages}
library(tidyverse)
library(janitor)
library(rstan)
library(bayesplot)
```

> **Note**: `rstan` is special. Follow installation guidelines from the course preface to set it up properly.

# Summary

Unit 2 is all about building your computational Bayesian toolbox:

- **Understand** how approximation helps where closed-form solutions fail.
- **Apply** MCMC to complex models in practice.
- **Diagnose** your simulations to ensure trust in your results.

You’re now prepared to dive into simulation-based Bayesian inference.


---


> **Note**: `rstan` is special. Follow installation guidelines from the course preface to set it up properly.

# 6.1 Grid Approximation

Grid approximation mimics viewing a high-resolution image by examining it through small windows. We approximate a continuous posterior density $f(\theta \mid y)$ by discretizing the parameter space into a finite grid and calculating posterior probabilities at these points.

## Steps for Grid Approximation

1. Define a discrete grid of possible $\theta$ values.
2. Evaluate the prior $f(\theta)$ and likelihood $L(\theta \mid y)$ at each grid value.
3. Compute unnormalized posteriors and normalize them.
4. Sample from this discrete posterior using weights.

### 6.1.1 A Beta-Binomial Example

Let $Y \mid \pi \sim \text{Bin}(10, \pi)$ and $\pi \sim \text{Beta}(2,2)$. Observing $Y=9$ yields a posterior $\pi \mid Y=9 \sim \text{Beta}(11,3)$. We'll forget the closed form and use grid approximation.

```{r grid-6-values}
# Step 1: Define a coarse grid
grid_data <- data.frame(pi_grid = seq(from = 0, to = 1, length = 6))

# Step 2: Evaluate prior and likelihood
grid_data <- grid_data %>% 
  mutate(prior = dbeta(pi_grid, 2, 2),
         likelihood = dbinom(9, 10, pi_grid))

# Step 3: Posterior approximation
grid_data <- grid_data %>% 
  mutate(unnormalized = likelihood * prior,
         posterior = unnormalized / sum(unnormalized))

# Check normalization
grid_data %>% summarize(sum(unnormalized), sum(posterior))

# Show posterior table
round(grid_data, 2)

# Step 4: Sample from posterior
set.seed(84735)
post_sample <- sample_n(grid_data, size = 10000, 
                        weight = posterior, replace = TRUE)

# Posterior sample table
post_sample %>% 
  tabyl(pi_grid) %>% 
  adorn_totals("row")

# Plot discretized posterior
library(ggplot2)
ggplot(grid_data, aes(x = pi_grid, y = posterior)) + 
  geom_point() + 
  geom_segment(aes(x = pi_grid, xend = pi_grid, y = 0, yend = posterior))

# Compare to true posterior
ggplot(post_sample, aes(x = pi_grid)) + 
  geom_histogram(aes(y = ..density..), color = "white") + 
  stat_function(fun = dbeta, args = list(11, 3)) + 
  lims(x = c(0, 1))
```

### Refinement: 101 Grid Values

```{r grid-101-values}
# Step 1: Finer grid
grid_data  <- data.frame(pi_grid = seq(from = 0, to = 1, length = 101))

# Step 2: Prior & likelihood
grid_data <- grid_data %>% 
  mutate(prior = dbeta(pi_grid, 2, 2),
         likelihood = dbinom(9, 10, pi_grid))

# Step 3: Posterior
grid_data <- grid_data %>% 
  mutate(unnormalized = likelihood * prior,
         posterior = unnormalized / sum(unnormalized))

# Plot smooth posterior
ggplot(grid_data, aes(x = pi_grid, y = posterior)) + 
  geom_point() + 
  geom_segment(aes(x = pi_grid, xend = pi_grid, y = 0, yend = posterior))

# Step 4: Sampling
set.seed(84735)
post_sample <- sample_n(grid_data, size = 10000, 
                        weight = posterior, replace = TRUE)

# Plot histogram with true posterior
ggplot(post_sample, aes(x = pi_grid)) + 
  geom_histogram(aes(y = ..density..), color = "white", binwidth = 0.05) + 
  stat_function(fun = dbeta, args = list(11, 3)) + 
  lims(x = c(0, 1))
```

---

Grid approximation, while limited in higher dimensions, provides an intuitive and visual approach to posterior approximation when the parameter space is low-dimensional.


---


### 6.1.2 A Gamma-Poisson Example

Let $Y_i \mid \lambda \overset{\text{iid}}{\sim} \text{Pois}(\lambda)$ for $i = 1, 2$ and $\lambda \sim \text{Gamma}(3,1)$. If we observe $Y_1 = 2$ and $Y_2 = 8$, the posterior is $\lambda \mid Y_1, Y_2 \sim \text{Gamma}(13, 3)$.

We'll use grid approximation to simulate from this posterior.

```{r gamma-poisson-grid}
# Step 1: Define a grid of 501 lambda values
grid_data   <- data.frame(lambda_grid = seq(from = 0, to = 15, length = 501))

# Step 2: Evaluate the prior & likelihood at each lambda
grid_data <- grid_data %>% 
  mutate(prior = dgamma(lambda_grid, 3, 1),
         likelihood = dpois(2, lambda_grid) * dpois(8, lambda_grid))

# Step 3: Approximate the posterior
grid_data <- grid_data %>% 
  mutate(unnormalized = likelihood * prior,
         posterior = unnormalized / sum(unnormalized))

# Step 4: Sample from the discretized posterior
set.seed(84735)
post_sample <- sample_n(grid_data, size = 10000, 
                        weight = posterior, replace = TRUE)

# Plot histogram with actual posterior overlay
ggplot(post_sample, aes(x = lambda_grid)) + 
  geom_histogram(aes(y = ..density..), color = "white") + 
  stat_function(fun = dgamma, args = list(13, 3)) + 
  lims(x = c(0, 15))
```

### 6.1.3 Limitations of Grid Approximation

Grid approximation is effective for simple, low-dimensional posteriors. But as the number of parameters increases, its feasibility diminishes due to the **curse of dimensionality**.

- For one parameter: we sweep a grid over one axis (e.g., $\pi$ from 0 to 1).
- For two parameters: the grid becomes a 2D mesh (like chopping both x and y axes in an image).
- For three or more: exponentially more grid points are needed to achieve the same resolution.

This leads to serious **computational inefficiency**. What took seconds for a univariate model may take hours or days (or more) in higher dimensions. In such cases, **Markov Chain Monte Carlo (MCMC)** methods are more practical and flexible alternatives.

Up next, we transition to understanding and applying MCMC simulation to overcome the shortcomings of grid approximation.

---


### 6.2 Markov Chains via `rstan`

**Markov chain Monte Carlo (MCMC)** refers to applying Markov chains to simulate from probability models. These methods scale effectively for complex Bayesian models, unlike grid approximation.

MCMC samples are not independent, and they are not drawn directly from the posterior distribution $f(\theta \mid y)$. Instead, each sample depends on the previous one, forming a **Markov chain**:

$$
\theta^{(i+1)} \sim f(\theta^{(i+1)} \mid \theta^{(i)}, y)
$$

This satisfies the **Markov property**:

$$
f(\theta^{(i+1)} \mid \theta^{(1)}, \ldots, \theta^{(i)}, y) = f(\theta^{(i+1)} \mid \theta^{(i)}, y)
$$

Despite these dependencies, MCMC algorithms can approximate the posterior distribution quite well. We'll use the **`rstan`** package to implement MCMC simulation.

### 6.2.1 A Beta-Binomial Example in `rstan`

We'll revisit the Beta-Binomial model $Y \sim \text{Bin}(10, \pi)$ and $\pi \sim \text{Beta}(2,2)$ with observed data $Y = 9$. 

#### Step 1: Define the Model

```{r define-rstan-model}
bb_model <- "
  data {
    int<lower = 0, upper = 10> Y;
  }
  parameters {
    real<lower = 0, upper = 1> pi;
  }
  model {
    Y ~ binomial(10, pi);
    pi ~ beta(2, 2);
  }
"
```

#### Step 2: Simulate the Posterior

```{r run-rstan-model, results='hide', message=FALSE}
library(rstan)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)

bb_sim <- stan(model_code = bb_model, data = list(Y = 9), 
               chains = 4, iter = 10000, seed = 84735)
```

#### Burn-in and Posterior Samples

`stan()` returns a `stanfit` object. It runs 4 chains, each of 10,000 iterations, discarding the first 5,000 as burn-in.

```{r burn-in-inspect}
as.array(bb_sim, pars = "pi") %>% head(4)
```

#### Trace Plot

```{r trace-plot, message=FALSE}
library(bayesplot)
mcmc_trace(bb_sim, pars = "pi", size = 0.1)
```

#### Histogram and Density Plot of Posterior Samples

```{r hist-dens-pi, message=FALSE}
mcmc_hist(bb_sim, pars = "pi") + 
  yaxis_text(TRUE) + 
  ylab("count")

mcmc_dens(bb_sim, pars = "pi") + 
  yaxis_text(TRUE) + 
  ylab("density")
```

These diagnostic plots confirm that the distribution of MCMC values closely matches the true $\text{Beta}(11, 3)$ posterior, even though values are not independent.

### 6.2.2 A Gamma-Poisson Example in `rstan`

Now we turn to the Gamma-Poisson model:

- $Y_i \mid \lambda \overset{\text{iid}}{\sim} \text{Poisson}(\lambda)$ for $i = 1,2$
- $\lambda \sim \text{Gamma}(3,1)$

Given observed data $Y = (2,8)$, the posterior is $\lambda \mid Y \sim \text{Gamma}(13,3)$.

#### Step 1: Define the Model

```{r define-gamma-poisson-model}
gp_model <- "
  data {
    int<lower = 0> Y[2];
  }
  parameters {
    real<lower = 0> lambda;
  }
  model {
    Y ~ poisson(lambda);
    lambda ~ gamma(3, 1);
  }
"
```

#### Step 2: Simulate the Posterior

```{r run-gamma-poisson-model, results='hide', message=FALSE}
gp_sim <- stan(model_code = gp_model, data = list(Y = c(2, 8)), 
               chains = 4, iter = 10000, seed = 84735)
```

### Diagnostic Plots for `\lambda`

```{r gamma-poisson-trace, message=FALSE}
mcmc_trace(gp_sim, pars = "lambda", size = 0.1)
```

```{r gamma-poisson-hist, message=FALSE}
mcmc_hist(gp_sim, pars = "lambda") + 
  yaxis_text(TRUE) + 
  ylab("count")
```

```{r gamma-poisson-dens, message=FALSE}
mcmc_dens(gp_sim, pars = "lambda") + 
  yaxis_text(TRUE) + 
  ylab("density")
```

These diagnostics confirm that the distribution of the 20,000 MCMC values closely approximates the true $\text{Gamma}(13,3)$ posterior. The histogram and density plots are slightly right-skewed, peak near $\lambda = 4$, and decline around the plausible support.


### 6.3 Markov Chain Diagnostics

Even when we can derive a Bayesian posterior, posterior simulation is useful for intuition and verification. And when a posterior can't be derived, simulation is essential. But because simulations are approximations, we must ask:

- What does a good Markov chain look like?
- How can we assess whether our chain approximates the posterior well?
- How large should our chain be?

There are no universal answers. But we begin with two visual tools — **trace plots** and **parallel chains** — followed by numerical diagnostics: **effective sample size**, **autocorrelation**, and **R-hat**.

### 6.3.1 Examining Trace Plots

Trace plots display parameter values over MCMC iterations. Ideally, they should resemble white noise. Consider problematic patterns:

- **Trend (Chain A)**: indicates non-convergence and strong correlation.
- **Sticking (Chain B)**: indicates poor mixing and potential posterior misrepresentation.

**Actionable steps:**

- Check model structure (priors, likelihood).
- Run chains for more iterations.

### 6.3.2 Comparing Parallel Chains

Each chain should look different but result in **similar posterior distributions**. Use `mcmc_dens_overlay()` to check agreement:

```{r overlay-densities, message=FALSE}
mcmc_dens_overlay(bb_sim, pars = "pi") + 
  ylab("density")
```

Simulate a short chain to demonstrate poor agreement:

```{r short-simulation, results='hide'}
bb_sim_short <- stan(model_code = bb_model, data = list(Y = 9), 
                     chains = 4, iter = 100, seed = 84735)
```

```{r trace-and-density-short}
mcmc_trace(bb_sim_short, pars = "pi")
mcmc_dens_overlay(bb_sim_short, pars = "pi")
```

### 6.3.3 Effective Sample Size & Autocorrelation

Effective sample size tells us how many **independent samples** the chain is worth:

```{r effective-sample-size}
neff_ratio(bb_sim, pars = c("pi"))
```

Autocorrelation indicates **dependency** among chain values:

```{r acf-plots, message=FALSE}
mcmc_trace(bb_sim, pars = "pi")
mcmc_acf(bb_sim, pars = "pi")
```

Try **thinning** to reduce autocorrelation:

```{r thinning, results='hide'}
thinned_sim <- stan(model_code = bb_model, data = list(Y = 9), 
                    chains = 4, iter = 10000, seed = 84735, thin = 10)
```

```{r thinning-check}
mcmc_trace(thinned_sim, pars = "pi")
mcmc_acf(thinned_sim, pars = "pi")
```

> Note: Thinning reduces sample size. It’s not always worth the loss in information.

### 6.3.4 Calculating R-hat

R-hat compares **between-chain** and **within-chain** variability. A value near 1 is ideal.

```{r rhat-value}
rhat(bb_sim, pars = "pi")
```

Values above 1.05 indicate that chains haven't converged to the same distribution.

---