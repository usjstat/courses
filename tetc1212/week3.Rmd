---
title: "STA 1142 - Probability and Distribution Theory I: Week 3"
author: "Dr. Rajitha M. Silva"
output: html_notebook
runtime: shiny
---

# 1.3 Axioms of Probability

Axioms form the foundation of probability theory. These are the basic rules or assumptions upon which all of probability is built. They allow us to develop a consistent mathematical framework for assigning and manipulating probabilities.

Understanding these axioms is important because:\

-   They ensure that the probability of any event is a meaningful, non-negative number.\
-   They guarantee the total probability across all possible outcomes equals 1.\
-   They help us handle more complex situations involving multiple events.

Probability is a numerical measure that quantifies the likelihood of an event occurring.

A probability function $\text{Pr}(\cdot)$ must satisfy these **three axioms**:

-   **Axiom 1**: For any event $A$, $\text{Pr}(A) \geq 0$
-   **Axiom 2**: $\text{Pr}(S) = 1$ (i.e., the total probability of the sample space is 1)
-   **Axiom 3**: For any countable collection of **mutually exclusive** events $A_1, A_2, \ldots$, $$ \text{Pr}(A_1 \cup A_2 \cup \ldots) = \sum_i \text{Pr}(A_i) $$

This holds for both **finite** and **countable infinite** unions.

------------------------------------------------------------------------

## Activity 1.13

Let $E$ be an event. Using the axioms of probability, show that $\text{Pr}(E) \leq 1$.

<details>

<summary><strong>Solution</strong></summary>

Let $E \subseteq S$. The complement of $E$, denoted $E^c$, is the set of outcomes in $S$ that are not in $E$.\
Using event operations, this can be expressed as:

$$
E^c = S \cap E^c
$$

Note:

\- $E \cap E^c = \emptyset$, so $E$ and $E^c$ are **mutually exclusive**.

\- $E \cup E^c = S$

By **Axiom 3** (additivity for mutually exclusive events):

$$
\text{Pr}(E \cup E^c) = \text{Pr}(E) + \text{Pr}(E^c)
$$

By **Axiom 2**:

$$
\text{Pr}(S) = 1
$$

Therefore:

$$
\text{Pr}(E) + \text{Pr}(E^c) = 1 \Rightarrow \text{Pr}(E) = 1 - \text{Pr}(E^c) \leq 1
$$

</details>

------------------------------------------------------------------------

# 1.4 Methods for Determining Probability

Probability can be determined in different ways depending on the context. Whether based on logical reasoning, past data, or subjective belief, each method has its own use case and importance.

Understanding these methods helps you:

\- Decide which model or approach fits a given situation.

\- Interpret probability values meaningfully.

\- Apply theory to real-world settings, such as games, experiments, or business problems.

There are four methods used to determine probabilities:

1.  **Classical Method**: Based on equally likely outcomes in a finite sample space.
2.  **Relative Frequency Method**: Based on repeated experiments and observed frequencies.
3.  **Subjective Method**: Based on personal judgment or opinion.
4.  **Using Probability Models**: Based on theoretical assumptions.

------------------------------------------------------------------------

## 1.4.1 Classical Method

The classical method of probability is the most basic and widely taught approach. It is grounded in situations where all outcomes are assumed to be **equally likely** - that is, each outcome has the same chance of occurring.

### What Does "Equally Likely" Mean?

Equally likely outcomes mean that, based on the design of the experiment or inherent symmetry, there is no reason to believe one outcome will happen more often than another. For example:

-   Each face of a fair die has a 1/6 chance.\
-   Each side of a fair coin has a 1/2 chance.\
-   Each card in a well-shuffled deck has a 1/52 chance.\

This method is especially useful when dealing with finite, symmetric, and well-defined sample spaces, such as dice rolls, card draws, or coin tosses.

If all outcomes in the sample space $S$ are equally likely, then for any event $E$:

$$
\text{Pr}(E) = \frac{n(E)}{n(S)}
$$

------------------------------------------------------------------------

## Activity 1.14

A fair six-sided die is rolled. Find the probabilities of the following events:

1.  $A$: getting the number 1\
2.  $B$: getting a number less than 3\
3.  $C$: getting an even number\
4.  $D$: getting a number greater than 5\
5.  $E$: getting a number greater than 6

------------------------------------------------------------------------

## Activity 1.15

A box contains:

\- 1 ticket with number 6

\- 2 tickets with number 5

\- 3 tickets with number 4

\- 4 tickets with number 3

\- 5 tickets with number 2

\- 6 tickets with number 1

A ticket is drawn at random. Find the probabilities of the following:

1.  Getting the number 1\
2.  Getting a number less than 3\
3.  Getting an even number\
4.  Getting a number greater than 5\
5.  Getting a number greater than 6

------------------------------------------------------------------------

# **Counting Techniques**

Counting techniques are essential tools in probability theory for calculating the number of possible outcomes in complex experiments. These techniques help us avoid the impractical task of listing every possible outcome when the number of outcomes grows large.

### 1. Multiplication Rule

If one task can be done in $m$ ways and another in $n$ ways, then the two tasks together can be performed in $m \times n$ ways.

**Example:** How many 3-digit PINs can be formed if each digit can be from 0 to 9? $$
10 \times 10 \times 10 = 1000 \text{ PINs}
$$

### 2. Permutations (Ordered Arrangements)

Permutations refer to the number of ways to arrange $r$ items out of $n$, when the order matters.

-   Formula (no repetition): $P(n, r) = \frac{n!}{(n - r)!}$

**Example:** How many ways can 3 medals (gold, silver, bronze) be awarded to 5 athletes? $$
P(n, r) = \frac{n!}{(n - r)!}
$$

$$
P(5, 3) = \frac{5!}{(5 - 3)!} = \frac{120}{2} = 60
$$

### 3. Combinations (Unordered Selections)

Combinations count how many ways $r$ elements can be selected from $n$, where the order doesn't matter.

-   Formula: $$
    C(n, r) = \binom{n}{r} = \frac{n!}{r!(n - r)!}
    $$

$$
\binom{10}{4} = \frac{10!}{4!6!} = 210
$$

**Example:** From 10 applicants, how many ways can a committee of 4 be formed? $$
\binom{10}{4} = 210
$$

These techniques help us for solving problems in probability, specially when dealing with complex events such as card games, lotteries, and arrangements.

------------------------------------------------------------------------

## Activity 1.16

A box contains 3 white balls and 2 black balls. Three balls are taken randomly from this box.\
If possible, find the probabilities of the following events using the classical method.\
Assume the 3 balls are drawn simultaneously (i.e., order does not matter).

1.  $A$: the event of getting exactly one white ball\
2.  $B$: the event of getting more than one white ball\
3.  $C$: the event of getting no white balls

## Activity 1.17

A security supervisor of a large corporation wishes to issue each employee an identity card with one English letter followed by two digits.

1.  How many different ID cards could be made if the two digits can be the same?
2.  How many different ID cards could be made if the two digits cannot be the same?
3.  How many different ID cards could be made if the first digit cannot be 0?

------------------------------------------------------------------------

## Activity 1.18

A box contains 3 white balls and 2 black balls. Three balls are taken randomly from this box. Assume that the balls are marked as $w_1, w_2, w_3, b_1, b_2$.

1.  How many different selections of three balls are possible?
2.  How many different arrangements of three balls are possible?
3.  Out of all the possible selections of three balls, how many selections contain 1 white ball?
4.  Out of all the possible arrangements of three balls, how many arrangements contain 1 white ball?
5.  Out of all the possible selections of three balls, how many selections contain 2 white balls?
6.  Out of all the possible arrangements of three balls, how many arrangements contain 2 white balls?

------------------------------------------------------------------------

## Activity 1.19

In a small company there are 7 women and 5 men. A committee of 5 people is to be selected.

1.  How many different committees can be selected?
2.  How many committees with 3 women and 2 men can be selected?
3.  If 5 people are selected at random for the committee, what is the probability that the committee consists of 3 women and 2 men?

------------------------------------------------------------------------

**When and Why We Multiply Probabilities**

In probability, we often deal with situations that involve **two or more events happening one after another**. To find the probability of such combined events, we apply the **Multiplication Rule** — a concept you've already seen in counting.

**Multiplication Rule (Counting):**

> If one task can be done in $m$ ways and another in $n$ ways, the tasks together can be done in $m \times n$ ways.

We apply the same idea in probability:

\
If an experiment involves multiple stages (like drawing two balls one after the other), we can find the probability of a specific sequence of outcomes by **multiplying the probability of each stage**, step by step.

> **Important**: Here, we are not assuming that the events are independent.\
> We are simply applying the multiplication rule in a **sequential setting**, where the outcome of the first event affects the second.\
> The concept of **independent events** will be formally discussed later in the course.

This will help us solve the problems in the next two activities.

------------------------------------------------------------------------

## Activity 1.20

A box contains 3 white balls and 2 black balls. Two balls are taken one after the other without replacement.

1.  What is the probability that the first ball is white?\
2.  What is the probability that the second ball is black?\
3.  What is the probability that the first ball is white and the second ball is black?

## Activity 1.21

A box contains 3 white balls and 2 black balls. Two balls are taken one after the other with replacement.

1.  What is the probability that the first ball is white?\
2.  What is the probability that the second ball is black?\
3.  What is the probability that the first ball is white and the second ball is black?

## Activity 1.22

A method that is often used to estimate the size of a wildlife population involves performing a **capture-recapture experiment**.

In this experiment:

-   An initial sample of $M$ animals is captured, tagged, and released into the wild.
-   Later, a second sample of size $n$ is captured (assume $n < M$).
-   Suppose the total number of animals in the population is $N$.
-   Let $x$ be the number of **tagged animals** in the second sample.

What is the probability that the second sample contains exactly $x$ tagged animals?

------------------------------------------------------------------------

## Activity 1.23

A production facility employs:

-   20 workers on the **day shift**
-   15 workers on the **swing shift** (between day and night, often running from 4:00 PM to midnight)
-   10 workers on the **graveyard shift** (Night Shift)

A quality control consultant is to select 6 workers at random **without replacement**.

1.  How many selections result in all six workers coming from the day shift? What is the probability that all six selected workers will be from the day shift?\

2.  What is the probability that all six selected workers will be from the same shift?\

3.  What is the probability that **at least two different shifts** will be represented among the selected workers?

------------------------------------------------------------------------

## 1.4.1 Relative Frequency Method

The **relative frequency method** is another way to estimate probability — specially useful when the theoretical model is difficult to define, or when real-world data is available from repeated observations.

### Key Ideas

-   Suppose we repeat an experiment many times under **identical and independent conditions**.
-   Let $E$ be an event we are interested in observing (e.g., getting a six when rolling a die).
-   Let $\text{freq}(E)$ be the number of times the event $E$ occurs in $n$ trials.

Then the **relative frequency** of event $E$ is:

$$
\text{Relative Frequency} = \frac{\text{freq}(E)}{n}
$$

As $n$ becomes large, the relative frequency tends to **stabilize**, approaching the **true probability** of the event. This leads us to the idea:

$$
\text{Pr}(E) = \lim_{n \to \infty} \frac{\text{freq}(E)}{n}
$$

This interpretation of probability is known as the **relative frequency definition**.

> **When to use:**\
> This method is especially helpful when you **collect data** from a real or simulated experiment and want to estimate the probability based on outcomes observed over many repetitions.

### Simulating an Example in R

We now explore how the relative frequency converges to the true probability as the number of trials increases.

```{r echo=FALSE}
library(shiny)

shinyApp(
  ui = fluidPage(
    titlePanel("Relative Frequency of Rolling a 6"),
    sidebarLayout(
      sidebarPanel(
        sliderInput("n", "Number of Trials:", 
                    min = 100, max = 10000, value = 1000, step = 100)
      ),
      mainPanel(
        plotOutput("freqPlot"),
        verbatimTextOutput("finalFreq")
      )
    )
  ),
  
  server = function(input, output) {
    output$freqPlot <- renderPlot({
      rolls <- sample(1:6, size = input$n, replace = TRUE)
      rel_freq <- cumsum(rolls == 6) / seq_along(rolls)
      
      plot(rel_freq, type = "l", col = "blue", lwd = 2,
           ylim = c(0, 0.4),
           xlab = "Number of Trials", 
           ylab = "Relative Frequency of Rolling a 6",
           main = "Convergence of Relative Frequency to Theoretical Probability")
      abline(h = 1/6, col = "red", lty = 2)
      legend("topright", legend = c("Relative Frequency", "True Probability = 1/6"),
             col = c("blue", "red"), lty = c(1, 2), bty = "n")
    })
    
    output$finalFreq <- renderPrint({
      rolls <- sample(1:6, size = input$n, replace = TRUE)
      rel_freq <- mean(rolls == 6)
      cat("Relative frequency after", input$n, "trials:", round(rel_freq, 4))
    })
  }
)
```

This estimates $\text{Pr}(6)$ as the proportion of sixes observed in 10,000 simulated rolls. If the die is fair, this value should be close to $1/6 \approx 0.1667$.

## Activity 1.24

In a certain production process, milk powder is filled into bags. A bag is said to be **‘non-conforming’** if its weight is **less than 398g or greater than 403g**. Otherwise, it is said to be **‘conforming’**.

The quality inspector has measured the weights of 585 randomly selected bags. The frequency table of those weights (in grams) is given below:

| Weight (in grams) | Number of Bags |
|:-----------------:|:--------------:|
|      396–397      |       10       |
|      398–399      |      175       |
|      400–401      |      270       |
|      402–403      |      115       |
|      404–405      |       15       |

1.  If a bag is taken randomly from the process, what is the probability that it will be a **non-conforming** bag?

2.  If three bags are taken randomly from the process, what is the probability that **one of them will be non-conforming**?

------------------------------------------------------------------------

## Activity 1.25

In a large manufacturing facility, an opinion survey was conducted regarding three types of bonus schemes. A random sample of 960 employees was selected. The job category and the bonus scheme of each employee were recorded. The results are shown below:

| Employee Category | Type I | Type II | Type III | Total |
|:-----------------:|:------:|:-------:|:--------:|:-----:|
|      Laborer      |  190   |   243   |   197    |  630  |
|       Clerk       |   82   |   44    |    44    |  170  |
|    Technician     |   23   |   78    |    34    |  135  |
|     Executive     |   5    |   12    |    8     |  25   |
|     **Total**     |  300   |   377   |   283    |  960  |

If an employee is selected randomly from this manufacturing facility, what is the probability that:

1.  The employee is a **clerk**?
2.  The employee has **bonus scheme II**?
3.  The employee is a **technician with bonus scheme I**?

------------------------------------------------------------------------

## 1.4.3 Subjective Probability Method

Not all situations allow us to calculate probabilities using past data (relative frequency) or symmetry (classical method). In such cases, we rely on **subjective probability**.

Subjective probability is based on a person’s **judgment, intuition, or personal belief** about how likely an event is to occur.

### Key Features

-   A **subjective probability** reflects an individual’s **opinion** about the occurrence of an event.
-   These probabilities are **personal** — they can **differ from person to person**, even when considering the same event.
-   It is often used when no past data or mathematical model is available.

### Limitations

-   Assigning a subjective probability can be difficult and may **lack consistency**.
-   There is **no objective way to verify** whether a subjective probability is correct.
-   The value can change with time, new information, or even mood.

### Common Approaches to Estimate Subjective Probabilities

-   **Personal guess** based on experience or intuition\
-   **Betting approach**: How much a person is willing to bet on an event indicates their belief in its occurrence\
-   **Reference lottery approach**: Comparing the uncertainty of the event to a known lottery

**Note**: While subjective probabilities are important in areas like decision making and risk analysis, this method will **not be discussed further in this course.**

The **subjective interpretation of probability** is a foundational idea in **Bayesian Statistics**, where probabilities are used to express **degrees of belief** rather than long-run frequencies.

Bayesian methods allow us to update our beliefs in light of new data using **Bayes’ Theorem**. These ideas are formally studied in a dedicated course on **Bayesian Inference**, offered to **Statistics Honours students in their fourth year**.

------------------------------------------------------------------------

## 1.4.4 Using Probability Models

In some situations, we do not rely on personal opinions (subjective method), experimental results (relative frequency), or symmetry (classical method). Instead, we use **mathematical models** to represent the behavior of random phenomena. These are called **probability models**.

A probability model defines:

-   A **sample space** — all possible outcomes of the experiment
-   A **probability function** — a rule that assigns probabilities to events in the sample space

This approach is common in scientific, engineering, and data-driven applications where the underlying process can be **described using theoretical assumptions**.

------------------------------------------------------------------------

### Key Features

-   Probability models are often **idealized representations** of real-world processes.
-   They allow us to **make predictions**, calculate **expected outcomes**, and assess **risks**.
-   These models are usually built using **probability distributions** such as:
    -   The binomial distribution (e.g., number of successes in a series of trials)
    -   The normal distribution (e.g., measurement errors, heights)
    -   The Poisson distribution (e.g., number of arrivals per minute)

------------------------------------------------------------------------

### Example

Suppose we are modeling the number of defective items in a batch of 100 products. We might assume that each item has a small, independent chance of being defective — and model the number of defectives using the **binomial distribution**.

Or, we might model the amount of rainfall in a day using a **continuous distribution** like the normal or exponential distribution.

> These kinds of probability models are specially useful in designing experiments, simulating systems, and making data-based decisions.

------------------------------------------------------------------------

**Note:**

A formal and detailed treatment of probability models and **probability distributions** will be covered in the **course on Probability Distribution Theory**, which is taught in the **second semester**.

There, you will learn to: - Recognize real-life situations that match standard distributions - Derive probabilities and expectations - Apply models to solve practical problems
